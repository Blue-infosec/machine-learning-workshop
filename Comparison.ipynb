{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":2,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\nfrom ipywidgets import interactive\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n     \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n     \"Naive Bayes\", \"SGDClassifier\"]\ndef f(datasets, shape,weights,classifier,data):\n\n    classifiers = [\n        KNeighborsClassifier(3),\n        SVC(kernel=\"linear\", C=0.025),\n        SVC(gamma=2, C=1),\n        GaussianProcessClassifier(1.0 * RBF(1.0)),\n        DecisionTreeClassifier(max_depth=5),\n        RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n        MLPClassifier(alpha=1, max_iter=1000),\n        AdaBoostClassifier(),\n        GaussianNB(),\n        SGDClassifier()]\n    \n    LX, Ly = make_classification(n_samples=200, n_features=2, n_redundant=0, n_informative=2,\n                           random_state=1, n_clusters_per_class=2, weights=[weights,1-weights])\n    rng = np.random.RandomState(2)\n    LX += shape * rng.uniform(size=LX.shape)\n    linearly_separable = (LX, Ly)\n\n    datasets_dict = {'moon': make_moons(n_samples=200, noise=shape/2, random_state=0),\n                'circle': make_circles(n_samples=200, noise=shape/2, factor=0.5, random_state=1),\n                'linear': linearly_separable}\n    \n    X = datasets_dict[datasets][0]\n    y = datasets_dict[datasets][1]\n    \n    cm = plt.cm.RdBu\n    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.05),\n                         np.arange(y_min, y_max, 0.05)) \n\n    clf = classifiers[names.index(classifier)]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n    clf.fit(X_train, y_train)\n#     score = clf.score(X_test, y_test)\n    if hasattr(clf, \"decision_function\"):\n        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n    else:\n        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n\n    Z = Z.reshape(xx.shape)\n    plt.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n    \n    # Plot also the training points\n    if data == 'train':\n        plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n                   edgecolors='k')\n    # and testing points\n    elif data == 'test':\n        plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n                   edgecolors='k', alpha=0.1)\n        plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n                   edgecolors='k')\n#     plt.scatter(datasets[2][0][:, 0], datasets[2][0][:, 1], marker='o', c=datasets[2][1], cmap=cm_bright, edgecolor='k')\n#     plt.show()\n    \ninteractive_plot = interactive(f, datasets=['moon', 'circle', 'linear'], shape=(0, 3, 0.1), weights=(0.05,0.99,0.05), \n                               classifier=names, data=['train', 'test'])\noutput = interactive_plot.children[-1]\noutput.layout.height = '400px'\ninteractive_plot","metadata":{"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"interactive(children=(Dropdown(description='datasets', options=('moon', 'circle', 'linear'), value='moon'), FloatSlider(value=1.0, description='shape', max=3.0), FloatSlider(value=0.5, description='weights', max=0.99, min=0.05, step=0.05), Dropdown(description='classifier', options=('Nearest Neighbors', 'Linear SVM', 'RBF SVM', 'Gaussian Process', 'Decision Tree', 'Random Forest', 'Neural Net', 'AdaBoost', 'Naive Bayes', 'SGDClassifier'), value='Nearest Neighbors'), Dropdown(description='data', options=('train', 'test'), value='train'), Output(layout=Layout(height='400px'))), _dom_classes=('widget-interact',))","text/html":"<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n<p>\n  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n  that the widgets JavaScript is still loading. If this message persists, it\n  likely means that the widgets JavaScript library is either not installed or\n  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n  Widgets Documentation</a> for setup instructions.\n</p>\n<p>\n  If you're reading this message in another frontend (for example, a static\n  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n  it may mean that your frontend doesn't currently support widgets.\n</p>\n","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a25d3ad357d4125a3c0f2f4c08324fe"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}