{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interactive\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "     \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "     \"Naive Bayes\", \"SGDClassifier\"]\n",
    "def f(datasets, shape,weights,classifier,data):\n",
    "\n",
    "    classifiers = [\n",
    "        KNeighborsClassifier(3),\n",
    "        SVC(kernel=\"linear\", C=0.025),\n",
    "        SVC(gamma=2, C=1),\n",
    "        GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "        DecisionTreeClassifier(max_depth=5),\n",
    "        RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "        MLPClassifier(alpha=1, max_iter=1000),\n",
    "        AdaBoostClassifier(),\n",
    "        GaussianNB(),\n",
    "        SGDClassifier()]\n",
    "    \n",
    "    LX, Ly = make_classification(n_samples=200, n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=2, weights=[weights,1-weights])\n",
    "    rng = np.random.RandomState(2)\n",
    "    LX += shape * rng.uniform(size=LX.shape)\n",
    "    linearly_separable = (LX, Ly)\n",
    "\n",
    "    datasets_dict = {'moon': make_moons(n_samples=200, noise=shape/2, random_state=0),\n",
    "                'circle': make_circles(n_samples=200, noise=shape/2, factor=0.5, random_state=1),\n",
    "                'linear': linearly_separable}\n",
    "    \n",
    "    X = datasets_dict[datasets][0]\n",
    "    y = datasets_dict[datasets][1]\n",
    "    \n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.05),\n",
    "                         np.arange(y_min, y_max, 0.05)) \n",
    "\n",
    "    clf = classifiers[names.index(classifier)]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "    clf.fit(X_train, y_train)\n",
    "#     score = clf.score(X_test, y_test)\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    else:\n",
    "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "    \n",
    "    # Plot also the training points\n",
    "    if data == 'train':\n",
    "        plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "                   edgecolors='k')\n",
    "    # and testing points\n",
    "    elif data == 'test':\n",
    "        plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "                   edgecolors='k', alpha=0.1)\n",
    "        plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "                   edgecolors='k')\n",
    "#     plt.scatter(datasets[2][0][:, 0], datasets[2][0][:, 1], marker='o', c=datasets[2][1], cmap=cm_bright, edgecolor='k')\n",
    "#     plt.show()\n",
    "    \n",
    "interactive_plot = interactive(f, datasets=['moon', 'circle', 'linear'], shape=(0, 3, 0.1), weights=(0.05,0.99,0.05), \n",
    "                               classifier=names, data=['train', 'test'])\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '400px'\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
